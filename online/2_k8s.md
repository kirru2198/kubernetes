# üìò Kubernetes Services: ClusterIP and NodePort ‚Äî With Practical Example

---

## ‚úÖ Introduction

In Kubernetes, **services** are used to expose applications running as **pods** so they can communicate internally (within the cluster) or externally (outside the cluster). 

In this session, we covered:

- Kubernetes service types
- Internal vs external communication
- ClusterIP vs NodePort services
- Deployment and service YAMLs
- Networking flow and port explanation
- Practical access via browser
- Security group updates in AWS EKS

---

## üîÑ Recap: Key Concepts

### 1. **Pods are Ephemeral**
- Pods in Kubernetes can come and go. Their IPs are not permanent.
- Direct communication with pods is unreliable due to changing IPs.

### 2. **Service in Kubernetes**
- Abstracts and exposes a set of pods using labels and selectors.
- Ensures stable access to applications regardless of pod IP changes.

---

## üåê Types of Communication in Kubernetes

### 1. **Internal Communication**
- Communication within the cluster.
- Achieved using **ClusterIP** service type.
  
### 2. **External Communication**
- Communication between outside world and cluster.
- Achieved using **NodePort** or **LoadBalancer** service types.

---

## üîß Deployment and Service YAMLs

### üìÑ `nginx-deployment.yaml`
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-deployment
  labels:
    app: nginx
spec:
  replicas: 3
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:latest
        ports:
        - containerPort: 80
```

### üìÑ `nginx-nodeport-service.yaml`
```yaml
apiVersion: v1
kind: Service
metadata:
  name: nginx-nodeport-service
  labels:
    app: nginx
spec:
  type: NodePort
  selector:
    app: nginx
  ports:
  - protocol: TCP
    port: 80           # Port exposed by the service
    targetPort: 80     # Port on the container (pod)
    nodePort: 30007    # Port exposed on the node
```

---

## üß† Understanding the Ports

| Term        | Description                                                                 |
|-------------|-----------------------------------------------------------------------------|
| `protocol`  | Defines the communication protocol (TCP/UDP) used by the service.           |
| `port`      | Port number the service listens on (inside the cluster).                   |
| `targetPort`| The container's (pod's) port the traffic should be forwarded to.            |
| `nodePort`  | Static port exposed on each worker node for external access (30,000‚Äì32767). |

### üîç Port Range for NodePort
- Default: `30000-32767` (Defined by Kubernetes/CNCF)
- You **can** specify a port or let Kubernetes auto-assign one from the range.

---

## üß™ Step-by-Step Deployment

### 1. Create the Deployment
```bash
kubectl apply -f nginx-deployment.yaml
```

### 2. Check the Pods
```bash
kubectl get pods -o wide
```

### 3. Create the NodePort Service
```bash
kubectl apply -f nginx-nodeport-service.yaml
```

### 4. View Services
```bash
kubectl get svc
```

### 5. View Endpoints
```bash
kubectl get endpoints
```

---

## üñ•Ô∏è Accessing Application via Browser

1. Get **node's public IP** (AWS EC2 instance):
   - Go to EC2 Console ‚Üí Instances ‚Üí Public IPv4 address

2. Access application using:
```
http://<Node_Public_IP>:30007
```

If it doesn't load:

3. Open port **30007** in the **EC2 security group**:
   - Go to EC2 ‚Üí Security Groups
   - Edit Inbound Rules ‚Üí Add TCP on 30007 ‚Üí Source: 0.0.0.0/0

---

## üéØ Network Flow Diagram (Conceptual)

```
Internet
   |
   v
[ NodePort on Node (30007) ]
   |
   v
[ Service (Port 80) ]
   |
   v
[ Pod (TargetPort 80, running nginx) ]
```

---

## üí° Key Takeaways

- **NodePort** allows external access to services via node IP and a specified port.
- Kubernetes services automatically perform **load balancing** to distribute traffic across multiple pods.
- The **`Endpoint`** object maps the service to live pods using their IPs.
- You must **manually open node ports** in cloud provider firewall rules (security groups in AWS).
- `kubectl get ep` confirms if service is correctly mapping to pod IPs.

---

## üõ°Ô∏è Best Practices

- Avoid creating custom security groups unless required.
- Let EKS create and manage security groups.
- For production-grade apps, prefer **LoadBalancer** type instead of NodePort.

---

## üîÑ Coming Up Next

> We'll explore the **LoadBalancer** service type which solves NodePort's limitations by creating an actual cloud load balancer (e.g., AWS ELB).

---
---

# üìò Kubernetes Networking & Service Types - Explained with Use Case and Challenges

## üîÅ Recap & Context

In this session, we are revisiting a crucial concept related to **Kubernetes Services**, especially focusing on **NodePort** and **LoadBalancer** service types. Let's walk through the communication patterns in Kubernetes, understand the limitations of NodePort, and see why LoadBalancer is often a better solution in cloud environments.

---

## üß† Types of Communication in Kubernetes

Kubernetes supports two main types of communication:

1. **Internal Communication**
2. **External Communication**

### üìå Internal Communication

- **Services** inside Kubernetes use a service type called `ClusterIP`.
- Example components involved:
  - `kube-apiserver` ‚áÑ `etcd`
  - `scheduler` ‚áÑ `kube-apiserver`
- These components talk to each other within the cluster.
- **Command Example:**

```bash
kubectl get svc
```

- You‚Äôll often see services of type `ClusterIP`, which are used only inside the cluster.

---

### üåç External Communication

- When exposing services to the **outside world**, we use different service types.
- One common type is `NodePort`.

---

## üö™ NodePort Service ‚Äì How It Works

### üîß Architecture

```
Client
   |
   ‚Üì
Node IP (NodePort)
   |
   ‚Üì
Kubernetes Service
   |
   ‚Üì
Pod (TargetPort)
```

### üí° Key Terms

| Term           | Description                          |
|----------------|--------------------------------------|
| **NodePort**   | Exposed port on the Kubernetes Node  |
| **Port**       | The service port                     |
| **TargetPort** | The port on the container/pod        |

### üìâ Challenges with NodePort

- You are **exposing your node directly to the internet**.
- You must **open ports manually** on the nodes.
- If you have multiple nodes, you need to **track multiple IPs and ports**.
- **Security risk**: You're essentially saying, *"Here is my public IP and open port."*
- Analogy: Like giving your apartment key to the public ‚Äì **not safe**!

---

## ‚úÖ Why We Avoid NodePort for External Traffic

- Difficult to manage across **large clusters** (e.g., 100+ nodes).
- **Hard to scale** and monitor.
- Security concerns due to **direct exposure**.
- In production, **NodePort is rarely used** for exposing apps to the internet.

---

## ‚öôÔ∏è The Better Alternative: LoadBalancer Service

### ‚òÅÔ∏è Cloud-Native Load Balancers

Most managed Kubernetes services (like **AWS EKS**, **Azure AKS**, **GCP GKE**) support **LoadBalancer** service type.

### üí° How It Works

```
Client
   |
   ‚Üì
Cloud Load Balancer (ALB/NLB)
   |
   ‚Üì
Kubernetes Service
   |
   ‚Üì
Pods (distributed across nodes)
```

### üìà Benefits

- No need to expose nodes or IPs directly.
- The cloud provider manages the **Load Balancer lifecycle**.
- **Scalable, secure**, and **easy to integrate** with DNS and domain names.
- You get a **DNS name** automatically when the LoadBalancer is created.

---

## üåê Real-World Example

Let‚Äôs say we want to deploy:

**`https://bookmyshow.com`**

- Instead of using the cloud load balancer‚Äôs raw DNS, we:
  1. Purchase a domain (e.g., `bookmyshow.com`)
  2. Create a **Route53 A-record**
  3. Point it to the cloud load balancer's DNS
- When a client hits the domain, traffic is routed securely and efficiently to the right pods.

---

## üõë NodePort vs LoadBalancer: Summary

| Feature                 | NodePort                       | LoadBalancer                         |
|------------------------|--------------------------------|--------------------------------------|
| Internet Exposure       | Direct (node IP + port)        | Indirect via cloud load balancer     |
| Security Risk           | High                           | Low                                  |
| Scalability             | Poor (manual IP/port mapping)  | Excellent (cloud-managed)            |
| DNS Integration         | Manual                         | Easy with cloud DNS                  |
| Recommended For         | Development/Test               | Production/Cloud                     |

---

## üì¶ Pod vs Container: Clarified

| Term       | Description |
|------------|-------------|
| **Container** | The actual instance running a specific process or logic (e.g., login logic) |
| **Pod**        | Abstraction over containers ‚Äì it can hold one or more containers. Provides management, networking, and shared storage between containers |

### üîÅ Sidecar Pattern

**Use Case Example**: Logging IP addresses

- One container: handles user login
- Second container: logs the user IP
- Both run inside the **same Pod** and **share resources**
- This is known as the **sidecar pattern**

---

## üß™ Lab Example: EFK Stack (Elasticsearch, Fluentd, Kibana)

We will explore LoadBalancer service in more detail during the **EFK stack setup** in an upcoming session. You'll see:

- Load balancer created via Kubernetes
- Pods receiving traffic through managed ALB/NLB
- Domain/DNS routing via Route 53

---

## ‚ùì Q&A Recap

> **Q: What is the use case of NodePort service?**  
> **A:** Rarely used in production. It's used for exposing services externally but comes with major security and scaling limitations. LoadBalancer is preferred.

> **Q: Difference between Pod and Container?**  
> **A:** A Pod is a wrapper around one or more containers. It provides extra features like shared networking and storage, especially useful for use cases like sidecar containers.

---

# üì¶ Kubernetes Storage Concepts

Kubernetes provides various mechanisms for managing **persistent storage**, enabling data to survive beyond the lifecycle of a Pod. This section covers essential storage components such as Volumes, Persistent Volumes (PV), Persistent Volume Claims (PVC), and StorageClasses.

---

## üìÅ Why Use Volumes in Kubernetes?

In Docker, we lose data when a container is deleted unless we explicitly mount a volume. Similarly, in Kubernetes:

- **Data stored inside a Pod is lost** when the Pod is deleted.
- **Solution**: Kubernetes provides **Volumes**, which persist data beyond the lifecycle of a Pod.

---

## üí° What is a Volume?

A **Kubernetes Volume** is a directory accessible to containers in a Pod. Unlike the container‚Äôs local filesystem, data in a volume can persist across container restarts and Pod deletions (if backed by persistent storage).

---

## üì¶ Types of Volumes

Kubernetes supports several types of volumes. Some of the common types are:

| Volume Type     | Description |
|-----------------|-------------|
| `emptyDir`      | Temporary storage, deleted when Pod is deleted. |
| `hostPath`      | Mounts a file/directory from the host node‚Äôs filesystem. |
| `configMap`     | Injects configuration data into Pods. |
| `secret`        | Injects sensitive data (like passwords or tokens). |
| `persistentVolume` (PV) | Abstraction of actual storage (local disk, NFS, cloud storage, etc). |

---

## üì¶ Persistent Volume (PV)

- **PV** is a **Kubernetes object** that represents a piece of storage in the cluster.
- Created by an **admin**.
- Can be backed by **cloud storage**, **NFS**, or **local storage**.

### Example PV YAML (Local Host Path):
```yaml
apiVersion: v1
kind: PersistentVolume
metadata:
  name: my-pv
spec:
  capacity:
    storage: 1Gi
  accessModes:
    - ReadWriteOnce
  hostPath:
    path: /mnt/data
```

---

## üßæ Persistent Volume Claim (PVC)

- A **PVC** is a **user's request** for storage.
- Defines **how much storage** is needed and the **access mode**.
- Kubernetes matches the PVC to an available PV.

### Example PVC YAML:
```yaml
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: my-pvc
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 1Gi
```

---

## üîó Binding PV and PVC

- A **PVC binds** to a suitable **PV**.
- Once bound, a **Pod** can mount the PVC and access the persistent storage.

---

## üöÄ Using PVC in a Pod

Here‚Äôs how a Pod uses a PVC to mount a persistent volume:

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: my-pod
spec:
  containers:
    - name: app-container
      image: nginx
      volumeMounts:
        - mountPath: "/usr/share/nginx/html"
          name: storage
  volumes:
    - name: storage
      persistentVolumeClaim:
        claimName: my-pvc
```

---

## ‚öôÔ∏è StorageClass

- A **StorageClass** defines **how to provision** storage dynamically.
- Useful for **cloud storage integration** (EBS, GCE PD, Azure Disk, etc).
- Acts like a **driver** that tells Kubernetes *how* to create volumes.

### Example StorageClass (for dynamic provisioning):
```yaml
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: fast-storage
provisioner: kubernetes.io/aws-ebs
parameters:
  type: gp2
```

---

## üìù Summary of Key Terms

| Term             | Description |
|------------------|-------------|
| **Volume**       | Temporary or persistent storage for a Pod. |
| **PersistentVolume (PV)** | Cluster-wide storage resource. |
| **PersistentVolumeClaim (PVC)** | A request for storage by a user. |
| **StorageClass** | Driver/config for dynamic provisioning. |

---

## üîç Coming Up: Services and Load Balancers

Storage is a foundation for deploying stateful applications. In upcoming sections, we will cover:

- Load Balancers and Services (especially in EFK Stack)
- Secrets and ConfigMaps
- StatefulSets and DaemonSets

These components enable running **real-world, stateful applications** in Kubernetes.

---

> üìå **Note**: Concepts will make more sense as we practice with real YAML examples and hands-on labs.
```
Wow, that was a super insightful and dense explanation ‚Äî your trainer has done a great job tying the pieces together! Let me break it down and summarize the key points, especially around the **`apiVersion`**, to help solidify your understanding:

---

### ‚úÖ **What is `apiVersion` in Kubernetes?**

The `apiVersion` in a Kubernetes YAML manifest tells Kubernetes **which version of the Kubernetes API to use** when handling the object you're defining.

#### üß† Think of it like:
> You're handing a form to the Kubernetes API ‚Äî the `apiVersion` tells it **which department and version of the form** to use so it knows how to interpret the contents.

---

### üì¶ **Kubernetes has many objects**, like:
- Pods
- Services
- Deployments
- ReplicaSets
- StatefulSets
- ConfigMaps
- Secrets
- PVs (PersistentVolumes)
- PVCs (PersistentVolumeClaims)
- etc.

---

### üìÅ Kubernetes Groups and Versions

Kubernetes categorizes its APIs into **groups**, and within each group, there are **versions**.

#### üîπ The structure:
```
apiVersion: <group>/<version>
```

#### Examples:
- `apiVersion: v1` ‚Üí Core group (no group prefix), stable version.
- `apiVersion: apps/v1` ‚Üí Belongs to the `apps` group, version `v1`.
- `apiVersion: batch/v1` ‚Üí Belongs to the `batch` group, version `v1`.
- `apiVersion: networking.k8s.io/v1` ‚Üí Belongs to the `networking.k8s.io` group.

> **Note**: Not all objects belong to the same API group.

---

### üìò Why Some Are Just `v1` (no group)?
That's the **core API group** ‚Äî it's the original set of Kubernetes objects (like Pods, Services, ConfigMaps, PersistentVolumes). They don‚Äôt need a prefix.

So:

```yaml
apiVersion: v1       # For core objects like Pod, Service, PV, PVC
apiVersion: apps/v1  # For Deployment, StatefulSet, DaemonSet
apiVersion: batch/v1 # For Jobs, CronJobs
```

---

### üìà What Do Versions Like `v1beta1`, `v1alpha1` Mean?
- `v1alpha1` ‚Äì Experimental, **not stable**, for early testing.
- `v1beta1` ‚Äì More stable, but **still subject to change**.
- `v1` ‚Äì Stable and **generally available (GA)**.

---

### üß∞ How to See Available API Versions?
Run:
```bash
kubectl api-versions
```

This will show you all the groups and versions your cluster supports.

---

### üîé How to Know Which `apiVersion` to Use for an Object?

**Two ways:**

1. üß≠ **Official Kubernetes Docs**
   - Example: https://kubernetes.io/docs/concepts/storage/persistent-volumes/
   - Look at the sample YAML ‚Äî it‚Äôll show the correct `apiVersion`.

2. üß™ **Using kubectl**
   - Run:
     ```bash
     kubectl explain <resource> | grep VERSION
     ```
     For example:
     ```bash
     kubectl explain deployment | grep VERSION
     ```

---

### üéÅ Extra Tip:
If you create a resource using `kubectl create` and then export it with `kubectl get <resource> -o yaml`, it will show you the **correct `apiVersion` automatically**.

---

### üóÇÔ∏è Trainer's GitHub Repository

That GitHub repo sounds like a **goldmine**. From labs to YAMLs to deep dives and even real-world scenarios, it‚Äôs an amazing supplement to your training.

You might want to bookmark the following from that repo:
- Labs for PV, PVC, StorageClass
- CKAD/CKA prep exercises
- Networking deep-dives
- RBAC (which is a slightly advanced topic)

---

### Summary:

| Resource         | apiVersion        | Group         |
|------------------|-------------------|----------------|
| Pod, Service, PV | `v1`              | Core           |
| Deployment       | `apps/v1`         | Apps           |
| Job, CronJob     | `batch/v1`        | Batch          |
| NetworkPolicy    | `networking.k8s.io/v1` | Networking |

---

Yes, Ravi! That‚Äôs exactly what‚Äôs happening here.

In Kubernetes terms:

- The **Persistent Volume (PV)** is like the pen drive ‚Äî it holds your data.
- The **Persistent Volume Claim (PVC)** is like plugging that pen drive into a laptop ‚Äî it requests access to the storage.
- The **Pod** is your laptop. It uses the PVC to access the volume.

When you deleted the pod (laptop), the data wasn‚Äôt deleted because the pen drive (PV) was still there. You just created a new pod (laptop) and plugged in the same PVC (claim), which pointed to the same PV (pen drive). So naturally, your file (`index.html`) was still there ‚Äî untouched and safe.

This example from your trainer was really spot-on. Does it feel clearer now? Want to go over the storage class part next?

---

Awesome! Let‚Äôs break down **Storage Class** now ‚Äî continuing with the same analogy:

---

### üöó Imagine this scenario:

You walk into a **storage shop** (the Kubernetes cluster) and say:

> ‚ÄúHey, I need a pen drive with these specs: 1 GB, fast speed, and automatically formatted and ready to use.‚Äù

Instead of picking a specific pen drive (PV), you just tell the shop **what kind** of pen drive you need.

---

### üí° That‚Äôs what a **StorageClass** does:

A `StorageClass` in Kubernetes is a **blueprint** or **template** that tells Kubernetes *how* to dynamically provision a Persistent Volume (PV) when a Persistent Volume Claim (PVC) is made.

So now instead of manually creating a PV ahead of time, you can just:

1. Define a `StorageClass` (e.g., with `gp2` in AWS, or `standard` in GKE).
2. Create a PVC that references this `StorageClass`.
3. Kubernetes will automatically create the PV using that `StorageClass`.

---

### üîÅ Connecting it to your flow:

- When you used a pre-created PV, the pod accessed it via a PVC.
- When you use a `StorageClass`, **you don't need to create a PV manually**.
  - You just create a PVC.
  - The PVC says: ‚ÄúHey, I want 1Gi of storage, and I want it based on this class.‚Äù
  - Kubernetes then creates a PV dynamically for you using that class.

---

### üß† TL;DR:
| Concept         | Analogy                     | Kubernetes Role                          |
|-----------------|-----------------------------|------------------------------------------|
| PV              | Pen drive                   | Actual storage                           |
| PVC             | Plugging pen drive into PC  | Request for storage                      |
| Pod             | Laptop                      | Uses storage via the claim               |
| StorageClass    | Pen drive *specification*   | Auto-creates storage based on your need  |

---

Wanna try an example with a `StorageClass`, `PVC`, and pod all in one YAML? Or maybe peek inside your trainer‚Äôs repo for one?

---

Sure! Here's a cleaned-up and organized **Markdown version** of your class session notes on **StorageClass**, with added explanations, structure, and headers to make it easier to study from:

---

# üì¶ Kubernetes StorageClass - Class Notes

---

## üéØ What is a StorageClass?

A **StorageClass** in Kubernetes provides a way for administrators to describe the **"classes" or types of storage** they offer. It allows Kubernetes to **dynamically provision Persistent Volumes (PV)** based on demand (PVCs).

### ‚úÖ Why is it needed?

In the previous approach:
- You created the **Persistent Volume (PV)** manually.
- Then, you created a **Persistent Volume Claim (PVC)** to bind it.
- This was **static provisioning** ‚Äî manual, error-prone, and inefficient.

With **dynamic provisioning**:
- You create **only the PVC**.
- The PVC refers to a `StorageClass`.
- Kubernetes automatically provisions the PV using the `StorageClass`.

---

## üõ†Ô∏è StorageClass Real-World Example with AWS EBS

In a real-world EKS (Elastic Kubernetes Service) cluster on AWS:
- The best place to store persistent data is an **EBS (Elastic Block Store) Volume**.
- To use EBS in Kubernetes, you need:
  - A **CSI Driver for AWS EBS**.
  - A properly configured **StorageClass** that uses this driver.

---

### üìÑ Example: StorageClass YAML

```yaml
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: standard
provisioner: kubernetes.io/aws-ebs
parameters:
  type: gp2
```

**Explanation:**
- `apiVersion`: API group for storage classes.
- `kind`: This is a `StorageClass`.
- `metadata.name`: Name of this storage class (`standard`).
- `provisioner`: The volume plugin/driver (`kubernetes.io/aws-ebs`).
- `parameters`: Additional config (in this case, `type: gp2` for general-purpose SSD EBS volume).

---

## üß† Key Points to Remember

| Concept            | Description |
|--------------------|-------------|
| Static Provisioning | Manually create PV, then bind via PVC |
| Dynamic Provisioning | PVC triggers automatic PV creation |
| StorageClass        | Template that tells K8s how to create storage |
| Provisioner         | The CSI or in-tree plugin used to create the storage (e.g., `aws-ebs`) |
| Parameters          | Define storage type, performance, etc. (e.g., `gp2`, `io1`) |

---

## üí° Why Dynamic Provisioning is Better?

Imagine this:
- You create a **1Gi PV**, but your app only needs **500Mi**.
- That‚Äôs **50% wasted storage**.

With dynamic provisioning:
- You write a **PVC requesting 500Mi**.
- A matching **PV is created on-the-fly** using the associated StorageClass.

No manual PV creation. Efficient and clean!

---

## üéì Summary

- `StorageClass` = Dynamic storage provisioning.
- You define **how** the storage should be created (using drivers like EBS, AzureDisk, etc.).
- Use **CSI Drivers** to enable cloud-native volumes like AWS EBS with Kubernetes.
- **Better approach** = PVC triggers dynamic PV creation using StorageClass.

---

## üìÖ Topics to Be Covered Tomorrow

Tomorrow‚Äôs class will include:

1. **Provisioning EBS Volume via StorageClass**
2. **ConfigMap**
3. **Secrets**
4. **Namespaces**
5. **RBAC**
6. **StatefulSet**
7. **DaemonSet**
8. **EFK Stack (Elasticsearch, Fluentd, Kibana)**
9. **LoadBalancer Services**
10. **Node Affinity / Taints & Tolerations**

> We'll implement all the above concepts **together in the EFK stack** to simulate real-world usage.

---

## üîó Bonus: Attend KubeCon if You Can!

- **KubeCon** is a major Kubernetes event.
- Try attending if you‚Äôre near Delhi or available online.
- Great for networking, job opportunities, and learning the latest in cloud-native tech.

---

## üßπ EKS Cluster Cleanup Tip

Don't forget to delete your **EKS cluster** after you're done with your lab sessions to avoid AWS charges!

```bash
eksctl delete cluster --name <your-cluster-name>
```

---

## üëã Final Notes

- Trainer will share files via GitHub.
- Feel free to connect with the trainer via LinkedIn or GitHub for queries.
- Tomorrow's class will bring everything together into a **real-world Kubernetes app deployment**.

---

