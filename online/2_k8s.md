# ğŸ“˜ Kubernetes Services: ClusterIP and NodePort â€” With Practical Example

---

## âœ… Introduction

In Kubernetes, **services** are used to expose applications running as **pods** so they can communicate internally (within the cluster) or externally (outside the cluster). 

In this session, we covered:

- Kubernetes service types
- Internal vs external communication
- ClusterIP vs NodePort services
- Deployment and service YAMLs
- Networking flow and port explanation
- Practical access via browser
- Security group updates in AWS EKS

---

## ğŸ”„ Recap: Key Concepts

### 1. **Pods are Ephemeral**
- Pods in Kubernetes can come and go. Their IPs are not permanent.
- Direct communication with pods is unreliable due to changing IPs.

### 2. **Service in Kubernetes**
- Abstracts and exposes a set of pods using labels and selectors.
- Ensures stable access to applications regardless of pod IP changes.

---

## ğŸŒ Types of Communication in Kubernetes

### 1. **Internal Communication**
- Communication within the cluster.
- Achieved using **ClusterIP** service type.
  
### 2. **External Communication**
- Communication between outside world and cluster.
- Achieved using **NodePort** or **LoadBalancer** service types.

---

## ğŸ”§ Deployment and Service YAMLs

### ğŸ“„ `nginx-deployment.yaml`
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-deployment
  labels:
    app: nginx
spec:
  replicas: 3
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:latest
        ports:
        - containerPort: 80
```

### ğŸ“„ `nginx-nodeport-service.yaml`
```yaml
apiVersion: v1
kind: Service
metadata:
  name: nginx-nodeport-service
  labels:
    app: nginx
spec:
  type: NodePort
  selector:
    app: nginx
  ports:
  - protocol: TCP
    port: 80           # Port exposed by the service
    targetPort: 80     # Port on the container (pod)
    nodePort: 30007    # Port exposed on the node
```

---

## ğŸ§  Understanding the Ports

| Term        | Description                                                                 |
|-------------|-----------------------------------------------------------------------------|
| `protocol`  | Defines the communication protocol (TCP/UDP) used by the service.           |
| `port`      | Port number the service listens on (inside the cluster).                   |
| `targetPort`| The container's (pod's) port the traffic should be forwarded to.            |
| `nodePort`  | Static port exposed on each worker node for external access (30,000â€“32767). |

### ğŸ” Port Range for NodePort
- Default: `30000-32767` (Defined by Kubernetes/CNCF)
- You **can** specify a port or let Kubernetes auto-assign one from the range.

---

## ğŸ§ª Step-by-Step Deployment

### 1. Create the Deployment
```bash
kubectl apply -f nginx-deployment.yaml
```

### 2. Check the Pods
```bash
kubectl get pods -o wide
```

### 3. Create the NodePort Service
```bash
kubectl apply -f nginx-nodeport-service.yaml
```

### 4. View Services
```bash
kubectl get svc
```

### 5. View Endpoints
```bash
kubectl get endpoints
```

---

## ğŸ–¥ï¸ Accessing Application via Browser

1. Get **node's public IP** (AWS EC2 instance):
   - Go to EC2 Console â†’ Instances â†’ Public IPv4 address

2. Access application using:
```
http://<Node_Public_IP>:30007
```

If it doesn't load:

3. Open port **30007** in the **EC2 security group**:
   - Go to EC2 â†’ Security Groups
   - Edit Inbound Rules â†’ Add TCP on 30007 â†’ Source: 0.0.0.0/0

---

## ğŸ¯ Network Flow Diagram (Conceptual)

```
Internet
   |
   v
[ NodePort on Node (30007) ]
   |
   v
[ Service (Port 80) ]
   |
   v
[ Pod (TargetPort 80, running nginx) ]
```

---

## ğŸ’¡ Key Takeaways

- **NodePort** allows external access to services via node IP and a specified port.
- Kubernetes services automatically perform **load balancing** to distribute traffic across multiple pods.
- The **`Endpoint`** object maps the service to live pods using their IPs.
- You must **manually open node ports** in cloud provider firewall rules (security groups in AWS).
- `kubectl get ep` confirms if service is correctly mapping to pod IPs.

---

## ğŸ›¡ï¸ Best Practices

- Avoid creating custom security groups unless required.
- Let EKS create and manage security groups.
- For production-grade apps, prefer **LoadBalancer** type instead of NodePort.

---

## ğŸ”„ Coming Up Next

> We'll explore the **LoadBalancer** service type which solves NodePort's limitations by creating an actual cloud load balancer (e.g., AWS ELB).

---
---

# ğŸ“˜ Kubernetes Networking & Service Types - Explained with Use Case and Challenges

## ğŸ” Recap & Context

In this session, we are revisiting a crucial concept related to **Kubernetes Services**, especially focusing on **NodePort** and **LoadBalancer** service types. Let's walk through the communication patterns in Kubernetes, understand the limitations of NodePort, and see why LoadBalancer is often a better solution in cloud environments.

---

## ğŸ§  Types of Communication in Kubernetes

Kubernetes supports two main types of communication:

1. **Internal Communication**
2. **External Communication**

### ğŸ“Œ Internal Communication

- **Services** inside Kubernetes use a service type called `ClusterIP`.
- Example components involved:
  - `kube-apiserver` â‡„ `etcd`
  - `scheduler` â‡„ `kube-apiserver`
- These components talk to each other within the cluster.
- **Command Example:**

```bash
kubectl get svc
```

- Youâ€™ll often see services of type `ClusterIP`, which are used only inside the cluster.

---

### ğŸŒ External Communication

- When exposing services to the **outside world**, we use different service types.
- One common type is `NodePort`.

---

## ğŸšª NodePort Service â€“ How It Works

### ğŸ”§ Architecture

```
Client
   |
   â†“
Node IP (NodePort)
   |
   â†“
Kubernetes Service
   |
   â†“
Pod (TargetPort)
```

### ğŸ’¡ Key Terms

| Term           | Description                          |
|----------------|--------------------------------------|
| **NodePort**   | Exposed port on the Kubernetes Node  |
| **Port**       | The service port                     |
| **TargetPort** | The port on the container/pod        |

### ğŸ“‰ Challenges with NodePort

- You are **exposing your node directly to the internet**.
- You must **open ports manually** on the nodes.
- If you have multiple nodes, you need to **track multiple IPs and ports**.
- **Security risk**: You're essentially saying, *"Here is my public IP and open port."*
- Analogy: Like giving your apartment key to the public â€“ **not safe**!

---

## âœ… Why We Avoid NodePort for External Traffic

- Difficult to manage across **large clusters** (e.g., 100+ nodes).
- **Hard to scale** and monitor.
- Security concerns due to **direct exposure**.
- In production, **NodePort is rarely used** for exposing apps to the internet.

---

## âš™ï¸ The Better Alternative: LoadBalancer Service

### â˜ï¸ Cloud-Native Load Balancers

Most managed Kubernetes services (like **AWS EKS**, **Azure AKS**, **GCP GKE**) support **LoadBalancer** service type.

### ğŸ’¡ How It Works

```
Client
   |
   â†“
Cloud Load Balancer (ALB/NLB)
   |
   â†“
Kubernetes Service
   |
   â†“
Pods (distributed across nodes)
```

### ğŸ“ˆ Benefits

- No need to expose nodes or IPs directly.
- The cloud provider manages the **Load Balancer lifecycle**.
- **Scalable, secure**, and **easy to integrate** with DNS and domain names.
- You get a **DNS name** automatically when the LoadBalancer is created.

---

## ğŸŒ Real-World Example

Letâ€™s say we want to deploy:

**`https://bookmyshow.com`**

- Instead of using the cloud load balancerâ€™s raw DNS, we:
  1. Purchase a domain (e.g., `bookmyshow.com`)
  2. Create a **Route53 A-record**
  3. Point it to the cloud load balancer's DNS
- When a client hits the domain, traffic is routed securely and efficiently to the right pods.

---

## ğŸ›‘ NodePort vs LoadBalancer: Summary

| Feature                 | NodePort                       | LoadBalancer                         |
|------------------------|--------------------------------|--------------------------------------|
| Internet Exposure       | Direct (node IP + port)        | Indirect via cloud load balancer     |
| Security Risk           | High                           | Low                                  |
| Scalability             | Poor (manual IP/port mapping)  | Excellent (cloud-managed)            |
| DNS Integration         | Manual                         | Easy with cloud DNS                  |
| Recommended For         | Development/Test               | Production/Cloud                     |

---

## ğŸ“¦ Pod vs Container: Clarified

| Term       | Description |
|------------|-------------|
| **Container** | The actual instance running a specific process or logic (e.g., login logic) |
| **Pod**        | Abstraction over containers â€“ it can hold one or more containers. Provides management, networking, and shared storage between containers |

### ğŸ” Sidecar Pattern

**Use Case Example**: Logging IP addresses

- One container: handles user login
- Second container: logs the user IP
- Both run inside the **same Pod** and **share resources**
- This is known as the **sidecar pattern**

---

## ğŸ§ª Lab Example: EFK Stack (Elasticsearch, Fluentd, Kibana)

We will explore LoadBalancer service in more detail during the **EFK stack setup** in an upcoming session. You'll see:

- Load balancer created via Kubernetes
- Pods receiving traffic through managed ALB/NLB
- Domain/DNS routing via Route 53

---

## â“ Q&A Recap

> **Q: What is the use case of NodePort service?**  
> **A:** Rarely used in production. It's used for exposing services externally but comes with major security and scaling limitations. LoadBalancer is preferred.

> **Q: Difference between Pod and Container?**  
> **A:** A Pod is a wrapper around one or more containers. It provides extra features like shared networking and storage, especially useful for use cases like sidecar containers.

---

# ğŸ“¦ Kubernetes Storage Concepts

Kubernetes provides various mechanisms for managing **persistent storage**, enabling data to survive beyond the lifecycle of a Pod. This section covers essential storage components such as Volumes, Persistent Volumes (PV), Persistent Volume Claims (PVC), and StorageClasses.

---

## ğŸ“ Why Use Volumes in Kubernetes?

In Docker, we lose data when a container is deleted unless we explicitly mount a volume. Similarly, in Kubernetes:

- **Data stored inside a Pod is lost** when the Pod is deleted.
- **Solution**: Kubernetes provides **Volumes**, which persist data beyond the lifecycle of a Pod.

---

## ğŸ’¡ What is a Volume?

A **Kubernetes Volume** is a directory accessible to containers in a Pod. Unlike the containerâ€™s local filesystem, data in a volume can persist across container restarts and Pod deletions (if backed by persistent storage).

---

## ğŸ“¦ Types of Volumes

Kubernetes supports several types of volumes. Some of the common types are:

| Volume Type     | Description |
|-----------------|-------------|
| `emptyDir`      | Temporary storage, deleted when Pod is deleted. |
| `hostPath`      | Mounts a file/directory from the host nodeâ€™s filesystem. |
| `configMap`     | Injects configuration data into Pods. |
| `secret`        | Injects sensitive data (like passwords or tokens). |
| `persistentVolume` (PV) | Abstraction of actual storage (local disk, NFS, cloud storage, etc). |

---

## ğŸ“¦ Persistent Volume (PV)

- **PV** is a **Kubernetes object** that represents a piece of storage in the cluster.
- Created by an **admin**.
- Can be backed by **cloud storage**, **NFS**, or **local storage**.

### Example PV YAML (Local Host Path):
```yaml
apiVersion: v1
kind: PersistentVolume
metadata:
  name: my-pv
spec:
  capacity:
    storage: 1Gi
  accessModes:
    - ReadWriteOnce
  hostPath:
    path: /mnt/data
```

---

## ğŸ§¾ Persistent Volume Claim (PVC)

- A **PVC** is a **user's request** for storage.
- Defines **how much storage** is needed and the **access mode**.
- Kubernetes matches the PVC to an available PV.

### Example PVC YAML:
```yaml
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: my-pvc
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 1Gi
```

---

## ğŸ”— Binding PV and PVC

- A **PVC binds** to a suitable **PV**.
- Once bound, a **Pod** can mount the PVC and access the persistent storage.

---

## ğŸš€ Using PVC in a Pod

Hereâ€™s how a Pod uses a PVC to mount a persistent volume:

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: my-pod
spec:
  containers:
    - name: app-container
      image: nginx
      volumeMounts:
        - mountPath: "/usr/share/nginx/html"
          name: storage
  volumes:
    - name: storage
      persistentVolumeClaim:
        claimName: my-pvc
```

---

## âš™ï¸ StorageClass

- A **StorageClass** defines **how to provision** storage dynamically.
- Useful for **cloud storage integration** (EBS, GCE PD, Azure Disk, etc).
- Acts like a **driver** that tells Kubernetes *how* to create volumes.

### Example StorageClass (for dynamic provisioning):
```yaml
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: fast-storage
provisioner: kubernetes.io/aws-ebs
parameters:
  type: gp2
```

---

## ğŸ“ Summary of Key Terms

| Term             | Description |
|------------------|-------------|
| **Volume**       | Temporary or persistent storage for a Pod. |
| **PersistentVolume (PV)** | Cluster-wide storage resource. |
| **PersistentVolumeClaim (PVC)** | A request for storage by a user. |
| **StorageClass** | Driver/config for dynamic provisioning. |

---

## ğŸ” Coming Up: Services and Load Balancers

Storage is a foundation for deploying stateful applications. In upcoming sections, we will cover:

- Load Balancers and Services (especially in EFK Stack)
- Secrets and ConfigMaps
- StatefulSets and DaemonSets

These components enable running **real-world, stateful applications** in Kubernetes.

---

> ğŸ“Œ **Note**: Concepts will make more sense as we practice with real YAML examples and hands-on labs.
```
Wow, that was a super insightful and dense explanation â€” your trainer has done a great job tying the pieces together! Let me break it down and summarize the key points, especially around the **`apiVersion`**, to help solidify your understanding:

---

### âœ… **What is `apiVersion` in Kubernetes?**

The `apiVersion` in a Kubernetes YAML manifest tells Kubernetes **which version of the Kubernetes API to use** when handling the object you're defining.

#### ğŸ§  Think of it like:
> You're handing a form to the Kubernetes API â€” the `apiVersion` tells it **which department and version of the form** to use so it knows how to interpret the contents.

---

### ğŸ“¦ **Kubernetes has many objects**, like:
- Pods
- Services
- Deployments
- ReplicaSets
- StatefulSets
- ConfigMaps
- Secrets
- PVs (PersistentVolumes)
- PVCs (PersistentVolumeClaims)
- etc.

---

### ğŸ“ Kubernetes Groups and Versions

Kubernetes categorizes its APIs into **groups**, and within each group, there are **versions**.

#### ğŸ”¹ The structure:
```
apiVersion: <group>/<version>
```

#### Examples:
- `apiVersion: v1` â†’ Core group (no group prefix), stable version.
- `apiVersion: apps/v1` â†’ Belongs to the `apps` group, version `v1`.
- `apiVersion: batch/v1` â†’ Belongs to the `batch` group, version `v1`.
- `apiVersion: networking.k8s.io/v1` â†’ Belongs to the `networking.k8s.io` group.

> **Note**: Not all objects belong to the same API group.

---

### ğŸ“˜ Why Some Are Just `v1` (no group)?
That's the **core API group** â€” it's the original set of Kubernetes objects (like Pods, Services, ConfigMaps, PersistentVolumes). They donâ€™t need a prefix.

So:

```yaml
apiVersion: v1       # For core objects like Pod, Service, PV, PVC
apiVersion: apps/v1  # For Deployment, StatefulSet, DaemonSet
apiVersion: batch/v1 # For Jobs, CronJobs
```

---

### ğŸ“ˆ What Do Versions Like `v1beta1`, `v1alpha1` Mean?
- `v1alpha1` â€“ Experimental, **not stable**, for early testing.
- `v1beta1` â€“ More stable, but **still subject to change**.
- `v1` â€“ Stable and **generally available (GA)**.

---

### ğŸ§° How to See Available API Versions?
Run:
```bash
kubectl api-versions
```

This will show you all the groups and versions your cluster supports.

---

### ğŸ” How to Know Which `apiVersion` to Use for an Object?

**Two ways:**

1. ğŸ§­ **Official Kubernetes Docs**
   - Example: https://kubernetes.io/docs/concepts/storage/persistent-volumes/
   - Look at the sample YAML â€” itâ€™ll show the correct `apiVersion`.

2. ğŸ§ª **Using kubectl**
   - Run:
     ```bash
     kubectl explain <resource> | grep VERSION
     ```
     For example:
     ```bash
     kubectl explain deployment | grep VERSION
     ```

---

### ğŸ Extra Tip:
If you create a resource using `kubectl create` and then export it with `kubectl get <resource> -o yaml`, it will show you the **correct `apiVersion` automatically**.

---

### ğŸ—‚ï¸ Trainer's GitHub Repository

That GitHub repo sounds like a **goldmine**. From labs to YAMLs to deep dives and even real-world scenarios, itâ€™s an amazing supplement to your training.

You might want to bookmark the following from that repo:
- Labs for PV, PVC, StorageClass
- CKAD/CKA prep exercises
- Networking deep-dives
- RBAC (which is a slightly advanced topic)

---

### Summary:

| Resource         | apiVersion        | Group         |
|------------------|-------------------|----------------|
| Pod, Service, PV | `v1`              | Core           |
| Deployment       | `apps/v1`         | Apps           |
| Job, CronJob     | `batch/v1`        | Batch          |
| NetworkPolicy    | `networking.k8s.io/v1` | Networking |

---

Yes, Ravi! Thatâ€™s exactly whatâ€™s happening here.

In Kubernetes terms:

- The **Persistent Volume (PV)** is like the pen drive â€” it holds your data.
- The **Persistent Volume Claim (PVC)** is like plugging that pen drive into a laptop â€” it requests access to the storage.
- The **Pod** is your laptop. It uses the PVC to access the volume.

When you deleted the pod (laptop), the data wasnâ€™t deleted because the pen drive (PV) was still there. You just created a new pod (laptop) and plugged in the same PVC (claim), which pointed to the same PV (pen drive). So naturally, your file (`index.html`) was still there â€” untouched and safe.

This example from your trainer was really spot-on. Does it feel clearer now? Want to go over the storage class part next?

---

Awesome! Letâ€™s break down **Storage Class** now â€” continuing with the same analogy:

---

### ğŸš— Imagine this scenario:

You walk into a **storage shop** (the Kubernetes cluster) and say:

> â€œHey, I need a pen drive with these specs: 1 GB, fast speed, and automatically formatted and ready to use.â€

Instead of picking a specific pen drive (PV), you just tell the shop **what kind** of pen drive you need.

---

### ğŸ’¡ Thatâ€™s what a **StorageClass** does:

A `StorageClass` in Kubernetes is a **blueprint** or **template** that tells Kubernetes *how* to dynamically provision a Persistent Volume (PV) when a Persistent Volume Claim (PVC) is made.

So now instead of manually creating a PV ahead of time, you can just:

1. Define a `StorageClass` (e.g., with `gp2` in AWS, or `standard` in GKE).
2. Create a PVC that references this `StorageClass`.
3. Kubernetes will automatically create the PV using that `StorageClass`.

---

### ğŸ” Connecting it to your flow:

- When you used a pre-created PV, the pod accessed it via a PVC.
- When you use a `StorageClass`, **you don't need to create a PV manually**.
  - You just create a PVC.
  - The PVC says: â€œHey, I want 1Gi of storage, and I want it based on this class.â€
  - Kubernetes then creates a PV dynamically for you using that class.

---

### ğŸ§  TL;DR:
| Concept         | Analogy                     | Kubernetes Role                          |
|-----------------|-----------------------------|------------------------------------------|
| PV              | Pen drive                   | Actual storage                           |
| PVC             | Plugging pen drive into PC  | Request for storage                      |
| Pod             | Laptop                      | Uses storage via the claim               |
| StorageClass    | Pen drive *specification*   | Auto-creates storage based on your need  |

---

Wanna try an example with a `StorageClass`, `PVC`, and pod all in one YAML? Or maybe peek inside your trainerâ€™s repo for one?

---

Sure! Here's a cleaned-up and organized **Markdown version** of your class session notes on **StorageClass**, with added explanations, structure, and headers to make it easier to study from:

---

# ğŸ“¦ Kubernetes StorageClass - Class Notes

---

## ğŸ¯ What is a StorageClass?

A **StorageClass** in Kubernetes provides a way for administrators to describe the **"classes" or types of storage** they offer. It allows Kubernetes to **dynamically provision Persistent Volumes (PV)** based on demand (PVCs).

### âœ… Why is it needed?

In the previous approach:
- You created the **Persistent Volume (PV)** manually.
- Then, you created a **Persistent Volume Claim (PVC)** to bind it.
- This was **static provisioning** â€” manual, error-prone, and inefficient.

With **dynamic provisioning**:
- You create **only the PVC**.
- The PVC refers to a `StorageClass`.
- Kubernetes automatically provisions the PV using the `StorageClass`.

---

## ğŸ› ï¸ StorageClass Real-World Example with AWS EBS

In a real-world EKS (Elastic Kubernetes Service) cluster on AWS:
- The best place to store persistent data is an **EBS (Elastic Block Store) Volume**.
- To use EBS in Kubernetes, you need:
  - A **CSI Driver for AWS EBS**.
  - A properly configured **StorageClass** that uses this driver.

---

### ğŸ“„ Example: StorageClass YAML

```yaml
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: standard
provisioner: kubernetes.io/aws-ebs
parameters:
  type: gp2
```

**Explanation:**
- `apiVersion`: API group for storage classes.
- `kind`: This is a `StorageClass`.
- `metadata.name`: Name of this storage class (`standard`).
- `provisioner`: The volume plugin/driver (`kubernetes.io/aws-ebs`).
- `parameters`: Additional config (in this case, `type: gp2` for general-purpose SSD EBS volume).

---

## ğŸ§  Key Points to Remember

| Concept            | Description |
|--------------------|-------------|
| Static Provisioning | Manually create PV, then bind via PVC |
| Dynamic Provisioning | PVC triggers automatic PV creation |
| StorageClass        | Template that tells K8s how to create storage |
| Provisioner         | The CSI or in-tree plugin used to create the storage (e.g., `aws-ebs`) |
| Parameters          | Define storage type, performance, etc. (e.g., `gp2`, `io1`) |

---

## ğŸ’¡ Why Dynamic Provisioning is Better?

Imagine this:
- You create a **1Gi PV**, but your app only needs **500Mi**.
- Thatâ€™s **50% wasted storage**.

With dynamic provisioning:
- You write a **PVC requesting 500Mi**.
- A matching **PV is created on-the-fly** using the associated StorageClass.

No manual PV creation. Efficient and clean!

---

## ğŸ“ Summary

- `StorageClass` = Dynamic storage provisioning.
- You define **how** the storage should be created (using drivers like EBS, AzureDisk, etc.).
- Use **CSI Drivers** to enable cloud-native volumes like AWS EBS with Kubernetes.
- **Better approach** = PVC triggers dynamic PV creation using StorageClass.

---

## ğŸ“… Topics to Be Covered Tomorrow

Tomorrowâ€™s class will include:

1. **Provisioning EBS Volume via StorageClass**
2. **ConfigMap**
3. **Secrets**
4. **Namespaces**
5. **RBAC**
6. **StatefulSet**
7. **DaemonSet**
8. **EFK Stack (Elasticsearch, Fluentd, Kibana)**
9. **LoadBalancer Services**
10. **Node Affinity / Taints & Tolerations**

> We'll implement all the above concepts **together in the EFK stack** to simulate real-world usage.

---

## ğŸ”— Bonus: Attend KubeCon if You Can!

- **KubeCon** is a major Kubernetes event.
- Try attending if youâ€™re near Delhi or available online.
- Great for networking, job opportunities, and learning the latest in cloud-native tech.

---

## ğŸ§¹ EKS Cluster Cleanup Tip

Don't forget to delete your **EKS cluster** after you're done with your lab sessions to avoid AWS charges!

```bash
eksctl delete cluster --name <your-cluster-name>
```

---

## ğŸ‘‹ Final Notes

- Trainer will share files via GitHub.
- Feel free to connect with the trainer via LinkedIn or GitHub for queries.
- Tomorrow's class will bring everything together into a **real-world Kubernetes app deployment**.

---

