# Kubernetes Recap & Rolling Updates   
**Topic:** Kubernetes Architecture, Objects, EKS Setup, and Rolling Updates

---

## ğŸ“Œ Topics Covered

### 1. **Kubernetes Architecture Overview**

Kubernetes has two primary layers:

#### **Control Plane**
Manages the overall cluster state.
- **kube-apiserver**: Acts as a communication hub; all components interact through it.
- **controller-manager**: Ensures that the current state matches the desired state.
- **scheduler**: Decides which pod should be placed on which node.
- **etcd**: A distributed key-value store used as Kubernetes' backing store for all cluster data.
> etcd: It's like a super-powered notepad that Kubernetes uses to keep track of everything happening in the clusterâ€”like which pods are running, configurations, secrets, and more. It stores all this information in a safe and reliable way, so Kubernetes always knows the current state of the system.

#### **Data Plane (Worker Nodes)**
Where application workloads run.
- **kubelet**: Agent that runs on each node, communicates with the API server.
- **container runtime**: Software like Docker or containerd to run containers.
- **kube-proxy**: Manages network rules and enables communication across services and pods.
> kube-proxy: Think of it as the traffic manager for your cluster. It helps your apps (pods and services) talk to each other by setting up the right network routes and making sure requests get to the right place.

---

### 2. **Key Kubernetes Objects**

- **Pod**: The smallest deployable unit in Kubernetes, representing a single instance of a running process.
> **Pod**: It's the smallest piece you can run in Kubernetes. You can think of it like a tiny box that holds your app (or part of it) and runs it. Each pod usually runs one container, and it's where your code actually lives and works inside the cluster.

- **ReplicaSet**: Maintains a stable set of replica Pods running at any given time.
  > ReplicaSet: Makes sure the right number of copies (replicas) of your pods are always running. If one goes down, it quickly brings up another to keep things running smoothly.
  - Automatically creates new Pods if existing ones are deleted.

---

### 3. **Demonstration Recap**

You created a **2-node EKS cluster** with the following steps:

#### âœ… **EKS Setup**
1. Created an EC2 instance.
2. Installed required tools:
   - `awscli`
   - `eksctl`
   - `kubectl`
3. Assigned IAM role to EC2.
4. Created cluster using:
   ```bash
   eksctl create cluster --name <cluster-name> --region <region> --node-type <instance-type>
   ```
5. Verified cluster creation using:
   ```bash
   kubectl get nodes
   ```

#### ğŸ§© **Cluster Structure**
- AWS manages the control plane.
- You connected via the EC2 instance to interact with the cluster.
- Pods are launched on worker nodes.

---

### 4. **Pods vs ReplicaSet**

- When a **Pod** is deleted manually, it doesnâ€™t come back.
- When a **ReplicaSet** is used, it maintains the desired count.  
  E.g., If 3 Pods are desired and 1 is deleted, a new one is automatically created.

---

### 5. **Deploying Applications in Kubernetes**

To deploy an application:
1. **Write application code**
2. **Create Dockerfile**
3. **Build Docker image**
4. **Reference image in Kubernetes Pod config**
  > Reference image in Kubernetes Pod config means telling Kubernetes which **Docker image** to use when creating the container inside the pod. Itâ€™s like giving it the recipe to know what app to run.
5. **Deploy using `kubectl apply`**

---

### 6. **Application Upgrade Strategy**

Letâ€™s say we have:

- **App Version 1.0**
- Code â†’ Dockerfile â†’ Docker Image â†’ Pod (3 replicas)

Now, you update the code (e.g., to Version 1.1), so:
- New code â†’ New Dockerfile â†’ New Image â†’ New Pod

#### âŒ **Bad Practice:**
Deleting old pods and applying new ones causes **downtime**.

---

### âœ… **Solution: Rolling Updates**

**Rolling Update** allows **zero-downtime deployments** by:
- Gradually replacing old Pods with new ones.
- Ensuring some instances of the app are always running.

---

## ğŸ”œ Whatâ€™s Next?

- Dive deeper into **Kubernetes Networking**
- Explore **etcd** in more detail
- Learn how **Rolling Updates** work with `Deployment` objects
- Possibly set up a **CI/CD pipeline** for automatic rolling updates

---

# ğŸš€ Kubernetes: Rolling Updates and Deployments Explained

## ğŸ“˜ What is a Rolling Update?

A **Rolling Update** is a deployment strategy in Kubernetes used to upgrade applications **without any downtime**. Instead of stopping the current version and launching a new one all at once, Kubernetes **gradually replaces old Pods with new ones**, ensuring the application is always up and running.

---

## ğŸ§  Concept of Rolling Update

Letâ€™s break it down with an example:

You have 3 Pods running with **application version 10**:
```
Pod-1 â†’ v10  
Pod-2 â†’ v10  
Pod-3 â†’ v10
```

Now, you want to upgrade to **version 11**. Hereâ€™s how the rolling update works:

1. **Step 1:** Kubernetes launches a new Pod with **version 11**:
   ```
   Pod-1 â†’ v10  
   Pod-2 â†’ v10  
   Pod-3 â†’ v10  
   Pod-4 â†’ v11
   ```

2. **Step 2:** Once the new Pod is running, it deletes one old Pod:
   ```
   Pod-2 â†’ v10 (deleted)  
   Remaining: Pod-1 (v10), Pod-3 (v10), Pod-4 (v11)
   ```

3. **Step 3:** It adds another new Pod with version 11:
   ```
   Pod-1 â†’ v10  
   Pod-3 â†’ v10  
   Pod-4 â†’ v11  
   Pod-5 â†’ v11
   ```

4. **Step 4:** Deletes another old Pod:
   ```
   Pod-1 â†’ v10 (deleted)  
   Remaining: Pod-3 (v10), Pod-4 (v11), Pod-5 (v11)
   ```

5. **Step 5:** Adds one final Pod with version 11:
   ```
   Pod-3 â†’ v10  
   Pod-4 â†’ v11  
   Pod-5 â†’ v11  
   Pod-6 â†’ v11
   ```

6. **Step 6:** Deletes the last old Pod:
   ```
   Pod-3 â†’ v10 (deleted)  
   Final Pods: Pod-4, Pod-5, Pod-6 â†’ All running version 11 âœ…
   ```

### âœ… Result:
- Your application is now fully upgraded to version 11.
- At no point was the application completely down.
- **Zero downtime**, smooth transition.

---

## âŒ Why Not Use ReplicaSet for Rolling Updates?

ReplicaSet can ensure a fixed number of Pods are running, but it doesnâ€™t handle **upgrades**.  
If you change the image version manually:
- You must **delete** existing Pods.
- Then **recreate** new ones.
- This results in **downtime**.

> ğŸ’¡ **ReplicaSet â‰  Rolling Updates**  
> For rolling updates, we use **Deployments**.

---

## âœ… Use Deployment for Rolling Updates

A **Deployment** manages ReplicaSets and enables rolling updates automatically.

Hereâ€™s a sample YAML for an NGINX deployment:

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-deployment
spec:
  replicas: 4
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
        - name: nginx
          image: nginx:latest
          ports:
            - containerPort: 80
```

### Apply the Deployment:
```bash
kubectl apply -f nginx-deployment.yaml
```

### Check Deployment Status:
```bash
kubectl get pods
kubectl get replicasets
kubectl get deployments
```

> ğŸ¯ Kubernetes will handle:
> - Creating ReplicaSet  
> - Rolling out new Pods -- Rolling out new Pods means slowly replacing the old Pods with new ones, so your app keeps running smoothly without any interruptions. It's like upgrading parts of your app one by one instead of shutting everything down at once. 
> - Cleaning up old Pods -- Cleaning up old Pods means removing the outdated Pods to keep things neat and make space for the new ones. 
> - Ensuring no downtime

---

## âš™ï¸ Behind the Scenes: How Kubernetes Creates a Pod

### Here's what happens step-by-step:

1. You run:
   ```bash
   kubectl apply -f nginx-pod.yaml
   ```
2. The YAML file is sent as an **API request** to the **Kube API Server**.
3. API Server identifies the object (`kind: Pod`) and passes it to the **Scheduler**.
4. The **Scheduler** chooses a node for the Pod based on resources.
5. The **Kubelet** on that node receives the instruction to launch the Pod.
6. **Kubelet** uses **Container Runtime** (like containerd or Docker) to pull the image and start the container.

---

## ğŸ“ Why We Don't Create Pods Directly

When you create a Pod directly and it gets deleted:
- It **does not come back** automatically.
- Thereâ€™s **no controller** managing it. -- No one is in charge of managing it.

To handle that, we use **ReplicaSets** or **Deployments**, which manage Pods for us.

---

## ğŸ”„ Summary

| Concept | Handles Pod Restart | Supports Updates | Downtime-Free |
|--------|----------------------|------------------|---------------|
| **Pod** | âŒ No                | âŒ No            | âŒ No          |
| **ReplicaSet** | âœ… Yes       | âŒ No            | âŒ No          |
| **Deployment** | âœ… Yes      | âœ… Yes           | âœ… Yes         |

---

# Understanding Pods, ReplicaSets, and Deployments in Kubernetes

### 1. **Overview of Deployment, ReplicaSet, and Pod**
In Kubernetes, we have three important components related to running applications: **Pods**, **ReplicaSets**, and **Deployments**. Letâ€™s look at each one and their roles in Kubernetes.

#### **Pod**
A Pod is the smallest deployable unit in Kubernetes, representing a single instance of a running process in a cluster.
> A Pod is the smallest deployable unit in Kubernetes, representing a single instance of a program or task running in a cluster.

#### **ReplicaSet**
A ReplicaSet ensures that a specified number of pod replicas are running at any given time. If any pod goes down, the ReplicaSet creates a new one to maintain the desired number of pods.

#### **Deployment**
A Deployment is a higher-level abstraction (= concept) that manages ReplicaSets and enables rolling updates to applications. Unlike ReplicaSets, Deployments offer more flexibility (= options), including the ability to handle rolling updates.

---

### 2. **Deployment Configuration** (= Setup)

Let's take a look at the deployment configuration. Below is the **nginx-deployment.yaml** that we will be using.

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-deployment
spec:
  replicas: 4
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:latest
        ports:
        - containerPort: 80
```

### Explanation of the Deployment YAML:
- `apiVersion: apps/v1`: Specifies the API version.
- `kind: Deployment`: Defines the object type as Deployment.
- `metadata`: Contains the name of the deployment (nginx-deployment).
- `spec`: Specifies the desired state:
  - `replicas: 4`: We want 4 replicas (pods) of the nginx application.
  - `selector`: Labels to match the Pods.
  - `template`: Defines the Pod template that includes the container configuration (nginx image in this case).

> Imagine you're in a library, and you want to find all the books by a particular author. 

> - **Books** are like **Pods** in Kubernetes.
> - **Labels** are like **book attributes** (e.g., author, genre, publication year).
> - The **selector** is like a **search filter** that helps you find all books by that author.

> So, when you set a selector, you're essentially saying, "I want to find all books where the author is 'John Doe'". The system will then go through all the books (pods) and bring back the ones that match the filter (the label).

> In Kubernetes, the selector helps the Deployment find and manage the Pods that match the specified labels.

---
The `template` in a Kubernetes Deployment is like a blueprint for creating Pods. Let's break down the components to make it easier to understand.

### Explanation:

- **template**: Think of it as a blueprint or a template for creating new Pods.
- **metadata**: This is like extra information or "tags" about the Pod.
- **labels**: Labels are key-value pairs that help identify and group related Pods. In this case, `app: nginx` means this Pod is labeled with "app" as the key and "nginx" as the value.

### Logical Example:

Imagine you're organizing a set of folders in a file cabinet. You have different folders for various projects, and each folder has a tag or label on it to help you find the folder later.

- Each **folder** represents a **Pod**.
- The **tag** on the folder is like a **label** in Kubernetes.

Now, suppose you are organizing folders for multiple teams, and you want to easily find all the folders related to the "nginx" project. You place a label on each folder (Pod) with the tag `app: nginx`. 

So, when you need to find all the folders related to "nginx," you can quickly look for the folders with the `app: nginx` label, just like how Kubernetes will use the label to find and manage the Pods.

In summary:
- The **template** is the blueprint for creating Pods.
- The **labels** are tags on each Pod, like â€œapp: nginx,â€ to identify them and help Kubernetes group or manage them more easily.
  
---

### 3. **Creating a ReplicaSet**

Hereâ€™s an example of a ReplicaSet configuration:

```yaml
apiVersion: apps/v1
kind: ReplicaSet
metadata:
  name: nginx-replicaset
  labels:
    app: nginx
spec:
  replicas: 3  
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:latest  
        ports:
        - containerPort: 80
```

### Explanation of the ReplicaSet YAML:
- `apiVersion: apps/v1`: Specifies the API version.
- `kind: ReplicaSet`: Defines the object type as ReplicaSet.
- `metadata`: Contains the name and labels.
- `spec`: Specifies the desired state:
  - `replicas: 3`: We want 3 replicas of the nginx pod.
  - `selector`: Labels to match the Pods.
  - `template`: Defines the Pod template (same as in the Deployment file).

---

### 4. **Pod Configuration Example**

Hereâ€™s an example of a basic Pod configuration:

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: nginx-pod
spec:
  containers:
  - name: nginx
    image: nginx:latest
    ports:
    - containerPort: 80
```

### Explanation of the Pod YAML:
- `apiVersion: v1`: Specifies the API version.
- `kind: Pod`: Defines the object type as Pod.
- `metadata`: Contains the name of the Pod (nginx-pod).
- `spec`: Defines the container running inside the Pod (nginx image in this case).

---

### 5. **How to Create and Manage Pods**

#### **Create a Pod**:
To create a pod using the `nginx-pod.yaml` file:

```bash
kubectl apply -f nginx-pod.yaml
```

This command will create the Pod. You can verify its creation by running:

```bash
kubectl get pods
```

#### **Delete a Pod**:
If you delete the Pod, it will not be recreated automatically unless it is managed by a ReplicaSet or Deployment:

```bash
kubectl delete pod nginx-pod
```

You will notice that the Pod does not automatically come back if it was created directly without any controller managing it.

#### **Delete a Pod Managed by a ReplicaSet**:
If you delete a Pod that is part of a ReplicaSet, it will automatically be recreated. This is because the ReplicaSet ensures the desired number of pods is maintained.

---

### 6. **Why Use Deployments Instead of Pods Directly?**

When using Kubernetes, it is recommended to use **Deployments** instead of creating Pods directly for several reasons:

1. **Automatic Management**: A Deployment will automatically manage the ReplicaSets, ensuring the desired state is always maintained. If you delete a Pod, it will be recreated.
   
2. **Rolling Updates**: Deployments offer the feature of rolling updates, which allow you to gradually update your application without any downtime.

3. **Scalability**: Deployments and ReplicaSets allow for easy scaling of your application by increasing or decreasing the number of replicas.

---

### 7. **Checking the Deployment and Pods**

To check the current state of your Deployments and Pods, you can use the following commands:

```bash
kubectl get deployments
kubectl get pods
```

If you want more details about a specific Deployment, you can use the `describe` command:

```bash
kubectl describe deployment nginx-deployment
```

---

### 8. **Summary of Key Concepts**

- **Pod**: The smallest unit in Kubernetes that runs a container.
- **ReplicaSet**: Ensures the desired number of Pods are always running.
- **Deployment**: Manages ReplicaSets, provides rolling updates, and simplifies the management of Pods.

In Kubernetes, we avoid creating Pods directly and instead use Deployments to leverage the benefits of rolling updates and automatic management.

---

### 9. **Conclusion**

By using **Deployments** in Kubernetes, we can take advantage of automatic rolling updates, replica management, and scalability features, making it easier to manage our application lifecycle without causing downtime. Instead of manually managing Pods or ReplicaSets, Kubernetes handles everything for us when we use Deployments.

---

# ğŸ“˜ Kubernetes Deployment and Rolling Update Strategy (EKS Example)

This document explains how **Kubernetes Deployments**, **ReplicaSets**, and **Pods** interact with each other, particularly in **Amazon EKS (Elastic Kubernetes Service)**. Weâ€™ll look into how information is fetched (= gathered) using `kubectl`, how updates are managed using the **rolling update strategy**, and how the **etcd database** plays a critical role in storing cluster state.

---

## ğŸ§  What is `etcd`?

- `etcd` is a **distributed key-value store** that acts as the **database of Kubernetes**.
- It stores **all cluster data**:
  - Nodes
  - Pods
  - Deployments
  - ReplicaSets
  - Configuration details
- Every time you run a `kubectl` command, the data comes from the `etcd` store.

---

## ğŸ” Describing a Deployment

### Command:
```bash
kubectl describe deployments.apps nginx-deployment
```

### Output Summary:
```yaml
Name:                   nginx-deployment
Namespace:              default
Replicas:               4 desired | 4 available
StrategyType:           RollingUpdate
RollingUpdateStrategy:  25% max unavailable, 25% max surge
Containers:
  - Image: nginx:latest
```

### Key Points:
- **Name**: Defined in your manifest YAML (`metadata.name`) -- ( = "Name: Defined in your configuration file (metadata.name).")
- **Namespace**: Kubernetes namespace where this deployment exists
- **Replicas**: Desired and actual pod counts
- **StrategyType**: `RollingUpdate` used for zero-downtime updates
- **Image**: The container image used (`nginx:latest`)

> ğŸ“Œ The `Deployment` object manages updates using the **RollingUpdate** strategy.

---

## ğŸ” Rolling Update Strategy

### From the Deployment:
```yaml
strategy:
  type: RollingUpdate
  rollingUpdate:
    maxUnavailable: 25%
    maxSurge: 25%
```

- **maxUnavailable**: Max pods that can be unavailable during the update
- **maxSurge**: Max extra pods that can be created during the update
- Ensures **zero downtime deployments**

---

## ğŸ“¦ Understanding ReplicaSets

### Command:
```bash
kubectl describe replicaset nginx-deployment-576c6b7b6
```

### Key Differences from Deployment:
- **No Rolling Update Strategy**
- **Controls the pods directly**
- Follows instructions from its parent Deployment

### Status Info:
```yaml
Replicas: 4 current | 4 desired
```

> ğŸ§© If `current` = `desired`, no action is taken. If thereâ€™s a mismatch, pods are created or terminated to match.

---

## âš™ï¸ Deployment â†’ ReplicaSet â†’ Pods

### Flow:
1. **Deployment** creates a **ReplicaSet**
2. **ReplicaSet** manages **Pods**

### Naming Convention:
- **Deployment Name**: `nginx-deployment`
- **ReplicaSet Name**: `nginx-deployment-576c6b7b6`
- **Pod Name**: `nginx-deployment-576c6b7b6-abcde`

This helps in identifying which pod belongs to which ReplicaSet and Deployment.

---

## ğŸ”„ Recreating Pods

### Deleting Pods:
```bash
kubectl delete pod <pod-name>
```

> Pods will be **automatically recreated** by the ReplicaSet to maintain desired state.

### Deleting Deployment:
```bash
kubectl delete deployment nginx-deployment
```

> This will clean up the **Deployment**, **ReplicaSet**, and **Pods**.

---

## ğŸ§ª Rolling Update Example (Upgrade)

You can simulate a rolling update by editing the image version in your Deployment YAML:
> "You can test a rolling update by changing the image version in your Deployment file."
> "To see how a rolling update works, change the image version in your Deployment file."

```yaml
containers:
- name: nginx
  image: nginx:1.25.1  # Newer version
```

Then apply the updated YAML:
```bash
kubectl apply -f nginx-deployment.yaml
```

Kubernetes will:
- Launch new pods with the updated image
- Terminate old pods
- Ensure service availability during update

---

## ğŸ› ï¸ Tools for Managing YAML Files

You donâ€™t always have to write Kubernetes YAMLs manually. Here are some helpful tools:
- **Kustomize** (built-in with kubectl)
- **Helm** (templating and package manager for K8s)
- **Kompose** (convert docker-compose to Kubernetes YAML)
- Online generators like:
  - [KubeYAML](https://kubeyaml.com/)
  - [K8s YAML Generator by Codefresh](https://codefresh.io/kubernetes-yaml-generator/)

---

## âœ… Summary

| Concept        | Object        | Description |
|----------------|---------------|-------------|
| Deployment     | High-level object | Manages updates, defines strategy |
| ReplicaSet     | Mid-level     | Ensures pod count matches desired |
| Pod            | Lowest-level  | Container(s) that run the app |
| etcd           | Database      | Stores the state of the cluster |
| Rolling Update | Strategy      | Enables zero-downtime updates |

---
---

# ğŸš€ Kubernetes Rolling Update Lab

This lab will guide you through **creating an NGINX deployment**, **applying rolling updates**, **scaling the deployment**, and **editing deployment configurations** using different methods. The goal is to help you understand how Kubernetes handles rolling updates and how you can interact (= work) with deployment configurations.

---

## ğŸ“˜ Prerequisites

- A Kubernetes cluster (Minikube, Kind, or a real cluster)
- `kubectl` installed and configured
- Basic understanding of Kubernetes objects (pods, deployments)

---

## ğŸ”¹ Step 1: Create an NGINX Deployment

We'll create an NGINX deployment with a specific image version (`1.21.6`).

### âœ… Deployment YAML

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-deployment
spec:
  replicas: 3
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:1.21.6
        ports:
        - containerPort: 80
```

### âœ… Apply the Deployment

```bash
kubectl apply -f nginx-deployment.yaml
```

---

## ğŸ” Step 2: Verify Deployment

Check if the pods and deployment are running correctly.

```bash
kubectl get deployments
kubectl get pods
kubectl describe deployment nginx-deployment
```

---

## ğŸ”„ Step 3: Scale the Deployment

### ğŸ“ˆ Scale Using `kubectl scale`

```bash
kubectl scale deployment nginx-deployment --replicas=5
```

### ğŸ“ˆ Scale Using `kubectl edit`

```bash
kubectl edit deployment nginx-deployment
```

- Look for the `replicas:` field and modify the number (e.g., change `5` to `8`).
- Save and exit.

### ğŸ“‰ Scale Down Using YAML

1. Modify `replicas` in the YAML file:

```yaml
replicas: 2
```

2. Reapply the YAML:

```bash
kubectl apply -f nginx-deployment.yaml
```

3. Verify:

```bash
kubectl get pods
```

---

## ğŸ› ï¸ Step 4: Modify the Deployment (Rolling Update)

To perform a **rolling update**, change the image version in the YAML.

### ğŸ“ Modify the Image Version

```yaml
        image: nginx:1.25.1
```

### ğŸ” Apply the Update

```bash
kubectl apply -f nginx-deployment.yaml
```

Kubernetes will **roll out the new pods** and terminate the old ones **gradually**.

---

## ğŸ§ª Edit Deployment Configurations â€“ Methods

| Method | Description | Safe? | Notes |
|--------|-------------|-------|-------|
| 1ï¸âƒ£ `kubectl scale` or other `kubectl` commands | Modify directly via command line | âœ… Safe | Quick for minor changes |
| 2ï¸âƒ£ `kubectl edit deployment` | Live edit of object from etcd | âš ï¸ Risky | Modifies live cluster state |
| 3ï¸âƒ£ Modify and re-apply YAML | Edit locally and reapply | âœ…âœ… Safest | Source of truth approach |

---

## âš ï¸ YAML Syntax Errors

YAML is **indent-sensitive**. A small mistake can break things. For example:

```yaml
replicas 5    # âŒ Missing colon
```

or

```yaml
containers:
- name: nginx
  image: nginx:1.21.6
     ports:              # âŒ Extra space
     - containerPort: 80
```

Kubernetes will throw a **YAML syntax error** during apply.

---

## ğŸŒ Kubernetes Official Docs

Refer to Kubernetes official docs for everything:

- ğŸ“˜ [https://kubernetes.io/docs](https://kubernetes.io/docs)
- ğŸ“˜ [https://k8s.io](https://k8s.io) (shorter version, redirects to the same site)

These are **official**, maintained by the **CNCF**, and are **your best reference** even during **certification exams (CKA/CKAD)**.

---

## âœ… Best Practices

- Always bookmark the [Kubernetes Docs](https://kubernetes.io/docs)
- YAML files act as source-of-truth â†’ version control them in Git
- Prefer modifying YAML and reapplying over editing live
- Stay regular and consistent in learning; Kubernetes evolves fast

---

## ğŸ“ Summary

| Task | Command |
|------|---------|
| Create deployment | `kubectl apply -f nginx-deployment.yaml` |
| Get pods | `kubectl get pods` |
| Describe deployment | `kubectl describe deployment nginx-deployment` |
| Scale deployment | `kubectl scale deployment nginx-deployment --replicas=5` |
| Edit deployment live | `kubectl edit deployment nginx-deployment` |
| Apply YAML after modification | `kubectl apply -f nginx-deployment.yaml` |

---
---

# ğŸš€ Kubernetes Rolling Updates & Deployment Image Changes

## ğŸ¯ Goal

To understand how **Kubernetes handles rolling updates** and how to interact with deployment configurations effectively.

---

## ğŸ“¦ Current Setup

- We have a **deployment** running `nginx` application.
- **Current replica count:** `2` (will scale to `8` for demonstration)
- **Image version:** `1.21.6`

---

## ğŸ§ª Step-by-Step Rolling Update Demo

### 1. **Scaling Up Pods**

```bash
kubectl scale deployment nginx-deployment --replicas=8
```

- This command increases the number of replicas to 8.
- Verify using:
  
```bash
kubectl get pods
```

---

### 2. **Ways to Upgrade the Image**

We want to upgrade from `1.21.6` to `1.23.3`. Here are three ways to do it:

---

### ğŸ”§ Method 1: Modify YAML File

1. Open the deployment YAML file.
2. Update the `image` field under `containers`.

```yaml
image: nginx:1.23.3
```

3. Apply the changes:

```bash
kubectl apply -f deployment.yaml
```

âœ… **Recommended method** â€” Keeps configuration version-controlled.

---

### âœï¸ Method 2: Use `kubectl edit`

```bash
kubectl edit deployment nginx-deployment
```

- Locate the `image:` line.
- Change the image tag.
- Save and exit â€” Kubernetes will handle the rolling update.

---

### ğŸ’» Method 3: Use `kubectl set image`

```bash
kubectl set image deployment/nginx-deployment nginx=nginx:1.23.3
```

- Instant CLI-based image change.
- Kubernetes initiates a rolling update immediately.

---

## ğŸ‘€ Live Monitoring with `watch`

```bash
watch kubectl get pods
```

- Continuously monitors pod state changes.
- Observe pods getting terminated and new ones getting created.

---

## ğŸ”„ Rolling Update Strategy

### Key Terms

- **Rolling Update Strategy**
- **maxSurge** = 25%
- **maxUnavailable** = 25%

### Example (With 100 pods):

| Step | Action |
|------|--------|
| 1 | Create 25 new pods |
| 2 | Delete 25 old pods |
| 3 | Repeat until all pods are updated |

Kubernetes ensures no downtime by overlapping old and new pods.

---

## ğŸ”½ Rolling Back (or Downgrading)

- You can apply the older image using the same methods as above (via YAML or CLI).
- Kubernetes handles downgrade similarly to an upgrade.

---

## ğŸ§  Key Observations

- **Pods are ephemeral** â€” They come and go. (Pods are temporary â€” they can be created and removed at any time.)
- **When pods are deleted:**
  - Pod name changes.
  - Pod IP changes.
- Therefore, **donâ€™t rely on Pod IPs** for communication.

---

## ğŸ•¸ï¸ Communication & Networking

- For consistent network access, Kubernetes provides **Services**.
- Services abstract pod IPs and offer a stable endpoint. (Services hide pod IPs and provide a constant access point.)

---

## ğŸ“Œ Extra Commands

### Check current pod details:

```bash
kubectl get pod -o wide
```

### Delete a pod:

```bash
kubectl delete pod <pod-name>
```

- Kubernetes automatically replaces it.

---

## ğŸ’¡ Tips & Tools

- Use [**Play with Kubernetes**](https://labs.play-with-k8s.com/) for hands-on practice â€” no setup needed.
- Great for beginners if you havenâ€™t set up an EKS or Minikube environment.

---

## âœ… Summary

| Task | Method |
|------|--------|
| Modify image safely | Update YAML and apply |
| Live changes | `kubectl edit` |
| Quick CLI change | `kubectl set image` |
| Observe changes | `watch kubectl get pods` |
| Networking solution | Use **Services** for stable communication |

---
---

# ğŸŒ Kubernetes Networking: Services Explained

---

## ğŸ§  Why Do We Need a Service in Kubernetes?

- Pods in Kubernetes have **dynamic IP addresses** â€” they can change if a pod is deleted or recreated.
- If other components want to talk to a pod, they can't rely on its IP.
- Hence, we need **Services** â€“ a stable way to **route traffic** to the correct pods.

### ğŸ“± Real-life Analogy

> Just like you need a **mobile number** to reach someone â€” in networking, you need an **IP address**.  
> But if that number keeps changing (like pod IPs), communication breaks down. A **service** is like a permanent contact that routes calls (requests) to the current number (pod).

---

## ğŸ” Types of Communication in Kubernetes

| Type | Description | Example |
|------|-------------|---------|
| **Internal** | Communication **within the cluster** | One pod talking to another |
| **External** | Communication **from outside the cluster** | Browser accessing your app |

---

## ğŸ“¦ Service Types in Kubernetes

| Service Type | Purpose | Use Case |
|--------------|---------|----------|
| **ClusterIP** | Default, for **internal communication** | Pod-to-pod within the cluster |
| **NodePort** | For **external access** on a static port | Access app from outside the cluster |

---

## ğŸ”§ Deployment and ClusterIP Service Setup

### 1. **Deployment: `nginx`**

```yaml
# nginx-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-deployment
  labels:
    app: nginx
spec:
  replicas: 3
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:latest
        ports:
        - containerPort: 80
```

Apply with:

```bash
kubectl apply -f nginx-deployment.yaml
```

---

### 2. **ClusterIP Service**

```yaml
# nginx-clusterip-service.yaml
apiVersion: v1
kind: Service
metadata:
  name: nginx-clusterip-service
  labels:
    app: nginx
spec:
  selector:
    app: nginx
  ports:
  - protocol: TCP
    port: 80
    targetPort: 80
  type: ClusterIP
```

Apply with:

```bash
kubectl apply -f nginx-clusterip-service.yaml
```

---

## ğŸ·ï¸ Understanding Labels and Selectors

- **Labels**: Key-value pairs used to **tag** resources. Example:  
  `app: nginx`
- **Selectors**: Used by Services to **target the right pods** using their labels.

> ğŸ’¡ Think of labels as **stickers** that identify a pod's role (like â€œlogin serviceâ€), and selectors as **rules** for choosing pods with the right stickers.

---

## ğŸ§© How It Works: Diagram View

```text
+----------------+             +-----------------------+
| Menu Pod       |  ----->     |  ClusterIP Service     |
+----------------+             +-----------------------+
                                      |
              ------------------------+-------------------------
              |                       |                        |
        +-----------+          +-----------+           +-----------+
        | Pod 1     |          | Pod 2     |           | Pod 3     |
        | app: nginx|          | app: nginx|           | app: nginx|
        +-----------+          +-----------+           +-----------+
```

- Traffic **always goes to the Service**, which **load balances** across matching pods.
- Service knows **which pods to forward traffic to** using the `selector`.

---

## ğŸ” Inspecting Resources

### View Pods with Labels

```bash
kubectl get pods --show-labels
```

### View Services

```bash
kubectl get svc
```

### Describe a Service

```bash
kubectl describe svc nginx-clusterip-service
```

---

## âš™ï¸ Internal Kubernetes Service

Kubernetes creates its own internal service called `kubernetes`:

```bash
kubectl get svc
```

Youâ€™ll see something like:

```
NAME             TYPE        CLUSTER-IP     PORT(S)   AGE
kubernetes       ClusterIP   10.96.0.1      443/TCP   1d
```

- ğŸ” This is used for internal communication between components like the scheduler, API server, etc.
- âš ï¸ **Do not delete this!**

---

## ğŸš€ Summary

| Concept | Purpose |
|--------|---------|
| **Service** | Stable endpoint to communicate with a set of pods |
| **ClusterIP** | For communication **inside the cluster** |
| **NodePort** | For exposing service **outside the cluster** |
| **Label** | Identifier/tag added to pods |
| **Selector** | Rule to match pods with the right label |
| **Load Balancing** | Service distributes traffic to multiple pods |

---

## ğŸ§  Key Takeaway

> A **Service** is your **bridge** to stable and scalable communication in Kubernetes.  
> Without it, your pods are like houses with changing addresses â€” unreachable and unreliable.

---
---

# ğŸ“¡ Kubernetes Services & Endpoints (with ClusterIP)

---

## ğŸ¯ Objective

Understand how **Services** and **Endpoints** work in Kubernetes â€” specifically focusing on the **ClusterIP** type. Weâ€™ll explore:

- How traffic is routed inside the cluster
- What happens when pods are deleted/recreated
- The role of the `Endpoints` object

---

## ğŸ“Œ Describe a Service in Kubernetes

```bash
kubectl describe svc nginx-clusterip-service
```

### ğŸ§¾ Sample Output:

```
Name:              nginx-clusterip-service
Namespace:         default
Labels:            app=nginx
Annotations:       <none>
Selector:          app=nginx
Type:              ClusterIP
IP:                10.100.139.23
Port:              <unset>  80/TCP
TargetPort:        80/TCP
Endpoints:         192.168.20.40:80,192.168.22.25:80,192.168.44.232:80
Session Affinity:  None
Events:            <none>
```

---

## ğŸ§© What is the Endpoint Field?

The `Endpoints` field lists the **pod IP addresses** that match the service's selector.

### âœ¨ Example:
```text
Endpoints: 192.168.20.40:80,192.168.22.25:80,192.168.44.232:80
```

These IPs are of the pods that the service will forward traffic to.

---

## ğŸ”„ What Happens When Pods Are Recreated?

- If you **delete a pod**, a new pod is created (by the deployment).
- The new pod gets a **new IP address**.
- The **Endpoints object** is **automatically updated** with the new IP.

### âœ… Confirm Pod IPs

```bash
kubectl get pods -o wide
```

### âœ… Recheck the Service

```bash
kubectl describe svc nginx-clusterip-service
```

Youâ€™ll see the new pod IPs reflected under `Endpoints`.

---

## ğŸ” Check the Endpoints Object

```bash
kubectl get endpoints
kubectl get ep
```

### ğŸ”¬ Describe It

```bash
kubectl describe endpoint nginx-clusterip-service
```

### ğŸ“Œ Key Observation:
- The **Endpoints object** is **automatically created** when a service is created.
- It has the **same name** as the service.
- It keeps track of all **live pod IPs** selected by the service's selector.

---

## ğŸ”ƒ How It Works (Flow Explanation)

1. You create a **Service** with a label selector.
2. Kubernetes creates a **matching Endpoints object**.
3. The Endpoints object tracks all **pod IPs** matching that label.
4. Traffic to the **Service IP** is **forwarded to pod IPs** via the endpoint.

### ğŸ” Auto-update:

- When pods die and new pods come up, **Endpoints is updated automatically**.

---

## ğŸ“Š Diagram Representation

```text
Client Pod
    |
    v
+-------------+
|  Service    |  <--- ClusterIP (Stable)
+-------------+
    |
    v
+-------------+       +-------------+       +-------------+
| Pod A (IP1) | <---> | Pod B (IP2) | <---> | Pod C (IP3) |
+-------------+       +-------------+       +-------------+
```

> The service routes traffic to any of the backend pods through the **Endpoints** object.

---

## ğŸ§  Concept Recap: Endpoints

| Term     | Description |
|----------|-------------|
| **Service** | Abstraction layer that exposes a set of pods via a stable IP |
| **Selector** | Used by service to identify which pods to route traffic to |
| **Endpoint** | Object created by Kubernetes that maintains the list of pod IPs |
| **ClusterIP** | Service type used for internal communication in the cluster |

---

## ğŸ”¥ Live Demo Flow (Recap)

1. Create a deployment with 3 pods.
2. Create a ClusterIP service with selector `app=nginx`.
3. Verify pod IPs.
4. Use `kubectl describe svc` to check the endpoint.
5. Delete any pod and see the endpoint auto-update.
6. Understand how Kubernetes routes internal traffic via the service & endpoint.

---

## ğŸ§ª Commands Used

```bash
kubectl get pods -o wide
kubectl delete pod <pod-name>
kubectl get svc
kubectl describe svc nginx-clusterip-service
kubectl get endpoints
kubectl describe endpoint nginx-clusterip-service
```

---

## ğŸ“… Coming Up Next

In the next session, we will:

- ğŸ”“ Explore **NodePort services** for **external access**
- ğŸ§  Compare **ClusterIP vs NodePort**
- âš–ï¸ Discuss **LoadBalancer services**
- ğŸš€ Deploy a real-world app and monitor it using the **EFK Stack (Elasticsearch + Fluentd + Kibana)**

---

## âœ… Homework

- Review today's concepts
- Practice creating deployments & services
- Delete and recreate pods to observe `Endpoints` behavior
- Be prepared to dive into **NodePort** and **real-world app monitoring** tomorrow!

---

## ğŸ“˜ Glossary

| Term        | Description |
|-------------|-------------|
| **ClusterIP** | Internal-only access |
| **NodePort**  | Exposes service on a static port on each node |
| **LoadBalancer** | Exposes service externally via cloud providerâ€™s load balancer |
| **Labels**      | Metadata to tag resources |
| **Selectors**   | Used by services to identify target pods |
| **Endpoints**   | Tracks real-time pod IPs for routing |

---

